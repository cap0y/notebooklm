import { Slide, SubtitleStyle } from '../types'
import { splitTextIntoChunks, getChunkIndexByCharacterCount } from './textUtils'

/**
 * 슬라이드 배열을 WebM 비디오로 렌더링
 *
 * Canvas + MediaRecorder를 사용하여 클라이언트 측에서 비디오 생성
 * 각 슬라이드의 이미지와 오디오(있는 경우)를 결합하고 자막을 오버레이
 */
export const exportVideo = async (
  slides: Slide[],
  width: number,
  height: number,
  subtitleStyle: SubtitleStyle,
  onProgress: (progress: number, msg: string) => void,
  includeSubtitles: boolean,
  externalCanvas?: HTMLCanvasElement,
): Promise<Blob> => {
  const canvas = externalCanvas || document.createElement('canvas')
  canvas.width = width
  canvas.height = height
  const ctx = canvas.getContext('2d')

  if (!ctx) throw new Error('Canvas context 생성 실패')

  const stream = canvas.captureStream(30) // 30 FPS
  const audioContext = new AudioContext()
  const dest = audioContext.createMediaStreamDestination()

  // 비디오(캔버스) + 오디오 스트림 결합
  const combinedTracks = [...stream.getVideoTracks(), ...dest.stream.getAudioTracks()]
  const combinedStream = new MediaStream(combinedTracks)

  const recorder = new MediaRecorder(combinedStream, {
    mimeType: 'video/webm;codecs=vp9',
  })

  const chunks: Blob[] = []
  recorder.ondataavailable = (e) => {
    if (e.data.size > 0) chunks.push(e.data)
  }

  // HEX 색상 → RGBA 문자열 변환 헬퍼
  const hexToRgba = (hex: string, alpha: number) => {
    const r = parseInt(hex.slice(1, 3), 16)
    const g = parseInt(hex.slice(3, 5), 16)
    const b = parseInt(hex.slice(5, 7), 16)
    return `rgba(${r}, ${g}, ${b}, ${alpha})`
  }

  return new Promise(async (resolve, reject) => {
    recorder.onstop = () => {
      const blob = new Blob(chunks, { type: 'video/webm' })
      audioContext.close()
      resolve(blob)
    }

    recorder.start()

    // 화면 방향에 따른 자막 최대 글자 수 결정
    const isPortrait = width < height
    const maxCharsPerLine = isPortrait ? 20 : 45

    for (let i = 0; i < slides.length; i++) {
      const slide = slides[i]
      onProgress((i / slides.length) * 100, `슬라이드 ${i + 1}/${slides.length} 렌더링 중...`)

      // 1. 이미지 로드
      const img = new Image()
      img.crossOrigin = 'anonymous'
      img.src = slide.imageUrl
      await new Promise((r) => {
        img.onload = r
      })

      // 2. 오디오 준비
      let duration = 3000 // 오디오 없으면 기본 3초
      let source: AudioBufferSourceNode | null = null

      if (slide.audioData) {
        duration = slide.audioData.duration * 1000
        source = audioContext.createBufferSource()
        source.buffer = slide.audioData
        source.connect(dest)
        source.start(audioContext.currentTime)
      }

      // 자막 청크 사전 계산
      const scriptText = slide.script || ''
      const textChunks = splitTextIntoChunks(scriptText, maxCharsPerLine)
      const totalChunks = textChunks.length

      // 3. 프레임 애니메이션 루프
      const startTime = performance.now()

      await new Promise<void>((resolveFrame) => {
        const drawFrame = () => {
          const now = performance.now()
          const elapsed = now - startTime
          const progress = Math.min(Math.max(elapsed / duration, 0), 1)

          // 검은 배경
          ctx.fillStyle = '#000'
          ctx.fillRect(0, 0, width, height)

          // 이미지 Contain 방식으로 그리기
          const scale = Math.min(width / img.width, height / img.height)
          const x = width / 2 - (img.width / 2) * scale
          const y = height / 2 - (img.height / 2) * scale
          ctx.drawImage(img, x, y, img.width * scale, img.height * scale)

          // 현재 자막 텍스트 결정
          let currentSubtitle = slide.subtitle
          if (slide.audioData && scriptText && totalChunks > 0) {
            const chunkIndex = getChunkIndexByCharacterCount(textChunks, progress)
            currentSubtitle = textChunks[chunkIndex]
          }

          // 자막 렌더링
          if (includeSubtitles && currentSubtitle) {
            const scaleFactor = Math.min(width, height) / 720
            const fontSize = subtitleStyle.fontSize * scaleFactor

            ctx.font = `bold ${fontSize}px ${subtitleStyle.fontFamily}, sans-serif`
            ctx.textAlign = 'center'
            ctx.textBaseline = 'middle'

            const textX = width / 2
            const textY = height * (subtitleStyle.verticalPosition / 100)

            const metrics = ctx.measureText(currentSubtitle)
            const textWidth = metrics.width
            const textHeight = fontSize * 1.2
            const padding = fontSize * 0.5

            // 배경 박스
            if (subtitleStyle.backgroundOpacity > 0) {
              ctx.fillStyle = hexToRgba(subtitleStyle.backgroundColor, subtitleStyle.backgroundOpacity)
              ctx.fillRect(
                textX - textWidth / 2 - padding,
                textY - textHeight / 2 - padding / 2,
                textWidth + padding * 2,
                textHeight + padding,
              )
            }

            // 텍스트
            ctx.fillStyle = subtitleStyle.color
            if (subtitleStyle.backgroundOpacity < 0.3) {
              ctx.shadowColor = 'rgba(0,0,0,0.8)'
              ctx.shadowBlur = 4
              ctx.lineWidth = fontSize * 0.05
              ctx.strokeStyle = 'black'
              ctx.strokeText(currentSubtitle, textX, textY)
            } else {
              ctx.shadowColor = 'transparent'
            }

            ctx.fillText(currentSubtitle, textX, textY)
          }

          if (elapsed < duration) {
            requestAnimationFrame(drawFrame)
          } else {
            resolveFrame()
          }
        }
        drawFrame()
      })

      if (source) {
        source.stop()
        source.disconnect()
      }
    }

    onProgress(100, '마무리 중...')
    recorder.stop()
  })
}

